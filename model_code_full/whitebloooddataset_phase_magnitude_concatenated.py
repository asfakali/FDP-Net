# -*- coding: utf-8 -*-
"""whitebloooddataset-phase-magnitude-concatenated.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KLy_I3bJP9-sBwkTCicurxi5DRvfhuD6
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from glob import glob
from random import randrange
import os
from time import time
import numpy as np
import seaborn as sns
from matplotlib import pyplot as plt
import pandas as pd
from PIL import Image
import torch
from torch import nn
import torch.nn.functional as F
from torch import optim
from torch.autograd import Variable
from torchvision import datasets, transforms, models
from torch.utils.data.sampler import SubsetRandomSampler
from sklearn.metrics import confusion_matrix,classification_report,RocCurveDisplay

import os

def count_files_in_directory(directory):
    file_count = 0
    # Walk through all directories and files in the given directory
    for root, dirs, files in os.walk(directory):
        file_count += len(files)
    return file_count

def count_files_in_subfolders(directory):
    subfolder_file_counts = {}

    def count_files_recursively(current_dir, parent_key=""):
        for item in os.listdir(current_dir):
            item_path = os.path.join(current_dir, item)
            if os.path.isdir(item_path):
                # Create a new key for the subfolder
                subfolder_key = os.path.join(parent_key, item)
                # Count files in this subfolder and add to dictionary
                file_count = count_files_in_directory(item_path)
                subfolder_file_counts[subfolder_key] = file_count
                # Recurse into the subfolder
                count_files_recursively(item_path, subfolder_key)

    count_files_recursively(directory)
    return subfolder_file_counts

# Path to the main directory
main_directory = '/kaggle/input/white-blood-cells-dataset'  # Replace with your directory path
#/content/drive/MyDrive/Aug_VDVWC/Annotation/Train
#main_directory = '/content/drive/MyDrive/Aug_VDVWC/Annotation/Train'

# Get the count of files in each subfolder
file_counts = count_files_in_subfolders(main_directory)

# Print the counts
for subfolder, count in file_counts.items():
    print(f'There are {count} files in the subfolder "{subfolder}"')

# pick CPU if GPU turns out to be unavailable
device = torch.device('cpu')

if torch.cuda.is_available():
    print('CUDA used:', torch.cuda.memory_allocated())
    device = torch.device('cuda')

# Define transforms for the training, validation, and testing sets
jitter_image = transforms.Compose([transforms.Resize((224,224)),
                                   transforms.RandomRotation(degrees=15),
                                   #transforms.ColorJitter(),
                                   transforms.RandomHorizontalFlip(),
                                   transforms.ToTensor(),
                                   transforms.Normalize([0.485, 0.456, 0.406],
                                                        [0.229, 0.224, 0.225])
                                   ])

clean_image = transforms.Compose([transforms.Resize((224,224)),
                                  transforms.ToTensor(),
                                  transforms.Normalize([0.485, 0.456, 0.406],
                                                       [0.229, 0.224, 0.225])])

root = '/kaggle/input/white-blood-cells-dataset'
# /kaggle/input/leukemia/Original

# Load the datasets
train_dataset = datasets.ImageFolder(
    root='/kaggle/input/white-blood-cells-dataset/Train',
    transform=jitter_image)

val_dataset = datasets.ImageFolder(
    root='/kaggle/input/white-blood-cells-dataset/Test-A',
    transform=jitter_image)
test_dataset = datasets.ImageFolder(
    root='/kaggle/input/white-blood-cells-dataset/Test-A',
    transform=jitter_image)

batch_size = 32 #In general, a larger batch size can lead to faster convergence and a better model performance, but it can also require more memory and computation. A smaller batch size can require more epochs to converge and may lead to a lower model performance, but it can be more memory-efficient and may be easier to fit on a single GPU.
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

import torch
import torch.nn as nn
import torch.nn.functional as F



class PointDepthwiseConv(nn.Module):
    def __init__(self, in_channels, out_channels, threshold=0.5, pointwise_kernel_size=1, depthwise_kernel_size=3, kernel_size = 3):
        super(PointDepthwiseConv, self).__init__()
        self.pointwise_conv = nn.Conv2d(in_channels, out_channels, kernel_size=pointwise_kernel_size, stride=1, padding=0)
        self.depthwise_conv = nn.Conv2d(in_channels, out_channels, kernel_size=depthwise_kernel_size, stride=1, padding=depthwise_kernel_size // 2, groups=in_channels//2)
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size // 2,  stride=1)

        self.layer_norm1 = nn.BatchNorm2d(out_channels)  # Layer Normalization after first convolutional layer
        self.layer_norm2 = nn.BatchNorm2d(out_channels)
        self.layer_norm3 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(int(out_channels*threshold), int(out_channels*threshold), kernel_size, padding=kernel_size // 2,  stride=1)

    def forward(self, x):
        x1 = (self.layer_norm1(self.pointwise_conv(x)))
        x2 = (self.layer_norm2(self.depthwise_conv(x)))

        x1 = x2*F.softmax(x1)
        x2 = x1*F.softmax(x2)
        x3 = (self.layer_norm3(self.conv(x)))


        x4 = x1*x2
        y3 = F.softmax(x4)
        x4= x3*y3

        return x4

class FinalModel(nn.Module):
    def __init__(self, in_channels=[4, 8, 16, 32, 64], out_channels= [8, 16, 32, 64, 128], num_classes =8 ):
        super(FinalModel, self).__init__()
        self.conv = nn.Conv2d(3, 4, 5, padding=5 // 2,  stride=1)
        self.layer_norm1 = nn.BatchNorm2d(4)
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.module = nn.ModuleList()
        for ic, oc in zip(self.in_channels, self.out_channels):
            self.module.append(PointDepthwiseConv(ic, oc))
        self.pooling = nn.ModuleList()
        for out_channel in out_channels:
            self.pooling.append(nn.MaxPool2d(2,2))#HW_wise(out_channel))

        self.upsample = nn.ModuleList()
        for out_channel in in_channels[1:][::-1]:
            self.upsample.append(nn.ConvTranspose2d(in_channels=out_channel*2, out_channels=out_channel, kernel_size=4, stride=2, padding=1))
        self.finalup = nn.ConvTranspose2d(in_channels=8, out_channels=6, kernel_size=4, stride=2, padding=1)
        self.maxpool = nn.MaxPool2d(7,7)#HW_wise(out_channels[-1], threshold=.3)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(128, 64)
        self.layer_norm2 = nn.BatchNorm1d(64)
        self.fc2 = nn.Linear(64, num_classes)
        self.softmax = nn.Softmax(dim=1)
    def forward(self, x):
        x = F.leaky_relu(self.layer_norm1(self.conv(x)))
        for layer, pooling in zip(self.module,self.pooling):
            x = layer(x)
            x = pooling(x)

        x1 = x
        for layer in self.upsample:
            x1 = layer(x1)

        x1 = self.finalup(x1)
        x = self.flatten(self.maxpool(x))


        return self.softmax(self.fc2(F.leaky_relu(self.layer_norm2(self.fc1(x))))), x1

model = FinalModel()
#model= nn.DataParallel(model)
model.to('cuda')

total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print("Total number of parameters:", total_params)

# apply our classifier to the densenet model
from torch.optim import lr_scheduler

# pick a criterion (loss function)
criterion = nn.CrossEntropyLoss()

loss_fn2 = nn.MSELoss()           # Loss function for task 2

# we want to only update the parameters of the classifier
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
epochs = 60
#scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, total_steps=epochs*240//2)

device = 'cuda'
val_loss_min = np.Inf  # initial best loss as infinite
model_save_name = 'whitebloodcellconcat.pt'
path = f'/kaggle/working/{model_save_name}'

import time
from tqdm import tqdm


training_losses,training_accuracies,validation_losses,validation_accuracies=[],[],[],[]


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
val_loss_min =  np.inf
for epoch in range(epochs):
    print('EPOCH', epoch)
    start_time = time.time()

    model.train()
    train_loss = 0.0
    accuracy_t = 0.0
    print('Training.', end='')
    for inputs, labels in tqdm(train_loader):
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs, fft_out = model(inputs)
        loss1 = criterion(outputs, labels)
        in_fft_mag = torch.abs(torch.fft.fftn(inputs, dim=[2, 3]))
        in_fft_phs = torch.angle(torch.fft.fftn(inputs, dim=[2, 3]))
        in_fft_phs = (in_fft_phs + torch.pi) / (2 * torch.pi)
        in_fft = torch.cat((in_fft_mag,in_fft_phs),axis=1)
        loss2 = loss_fn2(in_fft/torch.max(in_fft, dim=0, keepdim=True)[0], fft_out)
        loss = 3*loss1  + loss2
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        correct = (predicted == labels).sum().item()
        accuracy_t += correct / labels.size(0)

    model.eval()
    print('Validating', end='')
    with torch.no_grad():
        val_loss = 0.0
        accuracy = 0.0
        for inputs, labels in tqdm(val_loader):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs, fft_out = model(inputs)
            loss1 = criterion(outputs, labels)
            in_fft_mag = torch.abs(torch.fft.fftn(inputs, dim=[2, 3]))
            in_fft_phs = torch.angle(torch.fft.fftn(inputs, dim=[2, 3]))
            in_fft_phs = (in_fft_phs + torch.pi) / (2 * torch.pi)
            in_fft = torch.cat((in_fft_mag,in_fft_phs),axis=1)
            loss2 = loss_fn2(in_fft/torch.max(in_fft, dim=0, keepdim=True)[0], fft_out)
            loss = 3*loss1 + loss2
            val_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            correct = (predicted == labels).sum().item()
            accuracy += correct / labels.size(0)

    train_loss /= len(train_loader)
    accuracy_t /= len(train_loader)
    val_loss /= len(val_loader)
    accuracy /= len(val_loader)

    print(f'Training Loss: {train_loss:.3f}')
    print(f'Training Accuracy: {accuracy_t:.3f}')
    print(f'Validation Loss: {val_loss:.3f}')
    print(f'Validation Accuracy: {accuracy:.3f}')

    training_losses.append(train_loss)
    training_accuracies.append(accuracy_t)
    validation_losses.append(val_loss)
    validation_accuracies.append(accuracy)

    if val_loss <= val_loss_min:
        print(f'Saving model...')
        torch.save(model.state_dict(), path)
        val_loss_min = val_loss
    else:
        print('Not saving because not best epoch.')

    print(f'Time for epoch: {int(time.time() - start_time)} seconds\n')

plt.plot(np.arange(len(training_losses)),training_losses,label='Training Loss')
plt.plot(np.arange(len(training_accuracies)),training_accuracies,label='Training Accuracy')
plt.plot(np.arange(len(training_losses)),validation_losses,label='Validation Loss')
plt.plot(np.arange(len(training_losses)),validation_accuracies,label='Validation Accuracy')
plt.ylabel('Accuracy/Loss',fontsize=13)
plt.xlabel('Epoch',fontsize=13)
plt.title('Training Curve',fontsize=17)
plt.legend()
plt.savefig('training_leakyrelurmspromp.png')
plt.show()
#model.load_state_dict(torch.load('/kaggle/input/leakyrelurmspromp/Malaria.pt'))

def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)
total_params = count_parameters(model)
print(f"Total number of parameters in the model: {total_params}")

def testing(model, criterion):
    test_loss = 0.0
    correct   = 0.0
    total     = 0.0
    targets=[]
    predictions=[]

    for batch_idx, (data, target) in enumerate(test_loader):
        # move to GPU
        if torch.cuda.is_available():
            data, target = data.cuda(), target.cuda()
            model = model.cuda()
        # forward pass
        with torch.no_grad():
            output, x = model(data)
            loss = criterion(output, target)
        # update average test loss
        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))
        # convert output probabilities to predicted class
        pred = output.data.max(1, keepdim=True)[1]
        # compare predictions to true label
        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())
        total   += data.size(0)
        predictions.append(pred.cpu().numpy())
        targets.append(target.cpu().numpy())

    print('Test Loss: {:.6f}'.format(test_loss))
    print('Test Accuracy: %.3f%% (%2d/%2d)' % (100.00 * correct / total, correct, total))

    targets=np.array(targets)
    predictions=np.array(predictions)
    print(targets.shape,predictions.shape)
    conf=confusion_matrix(targets.reshape(-1,1),predictions.reshape(-1,1))

    sns.heatmap(conf,
                annot=True,
                fmt='g',
                xticklabels=['basophil','eosinophil','erythroblast','ig', 'lymphocyte', 'monocyte', 'neutrophil', 'platelet'],
                yticklabels=['basophil','eosinophil','erythroblast','ig', 'lymphocyte', 'monocyte', 'neutrophil', 'platelet'])
    plt.ylabel('Prediction',fontsize=13)
    plt.xlabel('Actual',fontsize=13)
    plt.title('Confusion Matrix',fontsize=17)
    plt.savefig('cm_leakyrelurmspromp.png')
    plt.show()
    print(classification_report(targets.reshape(-1,1), predictions.reshape(-1,1)))
    RocCurveDisplay.from_predictions(targets.reshape(-1,1), predictions.reshape(-1,1))
    plt.savefig('roc_leakyrelurmspromp.png')
    plt.show()

# data loaders
batch_size = 1 #In general, a larger batch size can lead to faster convergence and a better model performance, but it can also require more memory and computation. A smaller batch size can require more epochs to converge and may lead to a lower model performance, but it can be more memory-efficient and may be easier to fit on a single GPU.
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

testing(model, criterion)

def load_input_image(img_path):
    image = Image.open(img_path)
    # discard the transparent alpha channel and add the batch dimension
    image = clean_image(image)[:3,:,:].unsqueeze(0)
    return image

def predict_malaria(model, class_names, img_path):
    img = load_input_image(img_path)
    model = model.cpu()
    model.eval()
    idx = torch.argmax(model(img)[0])
    return class_names[idx]

